# RAGで苦労している話

## LLMの限界

LLMの限界の一つとして

「事前学習されなかった情報、最新情報などをに対応できない」

これに、対処するために考案されたのが、RAGつまり

「入力プロンプトに必要な情報を一緒に入れたらええやん？」

ということです。

ただし、LLMは入力プロンプトサイズの制限もあるので、

「入力プロンプトに入るサイズの情報まで絞り込む必要がある」

のです。

つまり、有象無象のテキスト情報の中から、応答に必要な最低限の情報を探し出してLLMのプロンプトに入力する必要があります。このための仕組みがRAGとなります。


## RAGの仕組み

一般的に、RAGでは、必要な情報を探し出すために、Embeddingというベクトル情報を使います。
(Embeddingについての説明は割愛)

- RAGの処理ステップ

  - 事前準備

    1. ファイルをセグメントに分割
    2. セグメント毎に、Embeddingを計算

  - 入力生成
  
    3. ユーザ入力からEmbeddingを計算
    4. Embeddingを使って、必要な情報を検索

  - 出力生成
  
    5. 必要な情報をLLMに入力して応答を生成する


## RAGを実装して試してみた結果

社内の公開可能なドキュメント類をRAGで検索する仕組みで、チャットボットを試作して評価してみました。

評価してみた結果、「なんかいまいち？？？」でした。

RAGの処理結果を細かく調べると、「関連している情報をとってこない」、「関係ない情報ばかりとってくる」という状況でした。もちろん、上手く必要な情報を持ってくるときもありましたが、ダメダメなケースが大多数でした。

この経験をもとに、OpenAIのEmbeddingモデルを再評価してみたので結果をまとめます。

## RAGに求めるもの

改めて、RAGに要求するものをまとめます。要するに、

  - 関連している箇所を拾って欲しい
  - 関連してない箇所は拾って欲しくない

この二つです。

## 評価手法

対象データ: 青空文庫より「走れメロス」

分割手法: tiktokenでカウントしつつ指定サイズに分割

Embeddingモデル: OpenAIの text-embedding-ada-002 text-embedding-3-small text-embedding-3-large

評価手法： 質問文のEmbeddingと、分割された対象データの各セグメントのEmbddingを評価関数に与えた結果をプロット

評価関数: L2距離、内積、コサイン類似度

## 評価結果

### 